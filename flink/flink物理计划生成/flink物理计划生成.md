# Flinkæ‰§è¡Œè®¡åˆ’ç”Ÿæˆ

## å‰è¨€

ä¸Šä¸€èŠ‚è®²åˆ°ä¸šåŠ¡ä»£ç `StreamExecutionEnvironment.execute()`ä¼šè§¦å‘jobçš„å®¢æˆ·ç«¯é€»è¾‘è®¡åˆ’`JobGraph` çš„ç”Ÿæˆï¼Œä¹‹åæ˜¯å®¢æˆ·ç«¯ä¸`JobManager`çš„äº¤äº’è¿‡ç¨‹

```java
//ClusterClient line388
public JobExecutionResult run(JobGraph jobGraph, ClassLoader classLoader) throws ProgramInvocationException {

   waitForClusterToBeReady();

   final LeaderRetrievalService leaderRetrievalService;
   try {
      leaderRetrievalService = LeaderRetrievalUtils.createLeaderRetrievalService(flinkConfig);
   } catch (Exception e) {
      throw new ProgramInvocationException("Could not create the leader retrieval service", e);
   }

   try {
      logAndSysout("Submitting job with JobID: " + jobGraph.getJobID() + ". Waiting for job completion.");
      this.lastJobExecutionResult = JobClient.submitJobAndWait(actorSystemLoader.get(),
         leaderRetrievalService, jobGraph, timeout, printStatusDuringExecution, classLoader);
      return this.lastJobExecutionResult;
   } catch (JobExecutionException e) {
      throw new ProgramInvocationException("The program execution failed: " + e.getMessage(), e);
   }
}
```
å…¶ä¸­`leaderRetrievalService = LeaderRetrievalUtils.createLeaderRetrievalService(flinkConfig);`æ˜¯å¯åŠ¨è·å– leader JobManager çš„æœåŠ¡ï¼Œflink æ”¯æŒ JobManager HAï¼Œéœ€è¦é€šè¿‡ leader JobManager è·å–å½“å‰çš„ leader JobManagerï¼Œç¨å¾®ä»‹ç»ä¸‹è¿™ä¸ªæœåŠ¡ï¼š

## JobManager Leader é€‰ä¸¾

å…ˆæ¥çœ‹è·å– `LeaderRetrievalService`çš„é€»è¾‘ï¼š

```java
//LeaderRetrievalUtils line61
public static LeaderRetrievalService createLeaderRetrievalService(Configuration configuration)
   throws Exception {

   RecoveryMode recoveryMode = getRecoveryMode(configuration);

   switch (recoveryMode) {
      case STANDALONE:
         return StandaloneUtils.createLeaderRetrievalService(configuration);
      case ZOOKEEPER:
         return ZooKeeperUtils.createLeaderRetrievalService(configuration);
      default:
         throw new Exception("Recovery mode " + recoveryMode + " is not supported.");
   }
}
```

é¦–å…ˆ flink ä¼šä¾æ®é…ç½®è·å– `RecoveryMode`ï¼Œ`RecoveryMode`ä¸€å…±ä¸¤ç§ï¼š*STANDALONE*å’Œ*ZOOKEEPER*ã€‚å¦‚æœç”¨æˆ·é…ç½®çš„æ˜¯*STANDALONE*ï¼Œä¼šç›´æ¥å»é…ç½®ä¸­è·å–`JobManager`çš„åœ°å€ï¼Œè¿™é‡Œä¸»è¦ä»‹ç»`ZOOKEEPER`æ¨¡å¼ä¸‹çš„`JobManager`leaderçš„å‘ç°è¿‡ç¨‹ï¼š

```java
//ZooKeeperUtils line141
public static ZooKeeperLeaderRetrievalService createLeaderRetrievalService(
      Configuration configuration) throws Exception {
   CuratorFramework client = startCuratorFramework(configuration);
   String leaderPath = configuration.getString(ConfigConstants.ZOOKEEPER_LEADER_PATH,
         ConfigConstants.DEFAULT_ZOOKEEPER_LEADER_PATH);

   return new ZooKeeperLeaderRetrievalService(client, leaderPath);
}

...
//ZooKeeperLeaderRetrievalService line103
	public void nodeChanged() throws Exception {
		try {
			LOG.debug("Leader node has changed.");

			ChildData childData = cache.getCurrentData();

			String leaderAddress;
			UUID leaderSessionID;

			if (childData == null) {
				leaderAddress = null;
				leaderSessionID = null;
			} else {
				byte[] data = childData.getData();

				if (data == null || data.length == 0) {
					leaderAddress = null;
					leaderSessionID = null;
				} else {
					ByteArrayInputStream bais = new ByteArrayInputStream(data);
					ObjectInputStream ois = new ObjectInputStream(bais);

					leaderAddress = ois.readUTF();
					leaderSessionID = (UUID) ois.readObject();
```

è¿™é‡Œ flink ä¼šé¦–å…ˆå°è¯•è¿æ¥ zookeeperï¼Œåˆ©ç”¨ zookeeperçš„leaderé€‰ä¸¾æœåŠ¡å‘ç°leaderèŠ‚ç‚¹çš„åœ°å€å’Œå½“å‰çš„ sessionidï¼Œsession idçš„ä½œç”¨ä»‹ç»`JobManager`çš„æ—¶å€™ä¼šè¯¦ç»†è¯´æ˜

## å®¢æˆ·ç«¯JobGraphçš„æäº¤

å®¢æˆ·ç«¯çš„`JobGraph`ç”Ÿæˆä¹‹åï¼Œé€šè¿‡ä¸Šé¢çš„`LeaderRetrivalService`è·å–`JobManager`çš„åœ°å€ï¼Œæ¥ä¸‹æ¥å°±æ˜¯å°†`JobGraph`æäº¤ç»™`JobManager`å»æ‰§è¡Œã€‚flink çš„æ ¸å¿ƒè¿›ç¨‹é€šä¿¡æ˜¯é€šè¿‡ Akka æ¥å®Œæˆçš„ï¼Œ`JobManager`ã€`TaskManager`éƒ½æ˜¯ä¸€ä¸ª Akka systemï¼Œæ‰€ä»¥è¿™é‡Œçš„æäº¤é¦–å…ˆéœ€è¦ç”Ÿæˆä¸€ä¸ªå®¢æˆ·ç«¯actorä¸`JobManager`äº¤äº’ï¼Œç„¶åæ‰§è¡Œrpcå‘½ä»¤ï¼Œå…·ä½“è§ï¼š

```java
//JobClient line98
public static JobExecutionResult submitJobAndWait(
      ActorSystem actorSystem,
      LeaderRetrievalService leaderRetrievalService,
      JobGraph jobGraph,
      FiniteDuration timeout,
      boolean sysoutLogUpdates,
      ClassLoader classLoader) throws JobExecutionException {

   ...

   // for this job, we create a proxy JobClientActor that deals with all communication with
   // the JobManager. It forwards the job submission, checks the success/failure responses, logs
   // update messages, watches for disconnect between client and JobManager, ...

   Props jobClientActorProps = JobClientActor.createJobClientActorProps(
      leaderRetrievalService,
      timeout,
      sysoutLogUpdates);

   ActorRef jobClientActor = actorSystem.actorOf(jobClientActorProps);
   
   // first block handles errors while waiting for the result
   Object answer;
   try {
      Future<Object> future = Patterns.ask(jobClientActor,
            new JobClientMessages.SubmitJobAndWait(jobGraph),
            new Timeout(AkkaUtils.INF_TIMEOUT()));
      
      answer = Await.result(future, AkkaUtils.INF_TIMEOUT());
   }
   ...
```

åœ¨`JobClientActor`å¯åŠ¨ä¹‹å‰ä¼šå¯åŠ¨`LeaderRetrivalService`ï¼Œ`LeaderRetrivalService`å¯åŠ¨ä¹‹åä¼šé€šçŸ¥å®ƒçš„ Listener `JobClientActor `è·å–` JobManager`çš„åœ°å€å’Œå½“å‰ session idã€‚ä¹‹åç»è¿‡æ¶ˆæ¯è·¯ç”±è·³è½¬åˆ°æäº¤çš„æ ¸å¿ƒé€»è¾‘ï¼š

```java
//JobClientActor line354
private void tryToSubmitJob(final JobGraph jobGraph) {
   this.jobGraph = jobGraph;

   if (isConnected()) {
      LOG.info("Sending message to JobManager {} to submit job {} ({}) and wait for progress",
         jobManager.path().toString(), jobGraph.getName(), jobGraph.getJobID());

      Futures.future(new Callable<Object>() {
         @Override
         public Object call() throws Exception {
            ActorGateway jobManagerGateway = new AkkaActorGateway(jobManager, leaderSessionID);

            LOG.info("Upload jar files to job manager {}.", jobManager.path());

            try {
               jobGraph.uploadUserJars(jobManagerGateway, timeout);
```

ä¸Šé¢çš„ä»£ç æœ‰æ‰€çœç•¥ğŸ˜ã€‚

æ€»ç»“ä¸‹ä¸Šé¢çš„è¿‡ç¨‹ï¼š

![jobclient-to-jobmanager](jobclient-to-jobmanager.png)

- å¯åŠ¨`JobClientActor`ç”¨æ¥å’Œ`JobManager`äº¤äº’
- å¯åŠ¨`LeaderRetrievalService`è·å–`JobManager`çš„åœ°å€
- ä¸Šä¼ ç”¨æˆ· jar åŒ…
- æäº¤ SubmitJob å‘½ä»¤

## JobManageræ‰§è¡Œè®¡åˆ’ç”Ÿæˆ

`JobManager`è´Ÿè´£æ¥æ”¶ flink çš„ä½œä¸šï¼Œè°ƒåº¦ taskï¼Œæ”¶é›† job çš„çŠ¶æ€ã€ç®¡ç† TaskManagersã€‚è¢«å®ç°ä¸ºä¸€ä¸ª akka actorã€‚

å®¢æˆ·ç«¯ä¸Šä¼ å®Œ jar åŒ…å’Œ`JobGraph`ï¼Œflink ä¼šè¿›ä¸€æ­¥è§£æå°è£…æˆè¿è¡Œæ—¶çš„æ‰§è¡Œè®¡åˆ’`ExecutionGraph`ï¼Œ`JobManager`çš„æ„é€ å™¨åœ¨åˆå§‹åŒ–çš„æ—¶å€™ä¼ å…¥äº†å¾ˆå¤šç»„ä»¶ï¼Œè¿™é‡Œç®€å•åˆ—ä¸¾ä¸‹åŠŸèƒ½æ–¹ä¾¿åé¢çš„é€»è¾‘å±•å¼€ï¼Œå…·ä½“çš„ç»†èŠ‚å°†ä¼šåœ¨ä¸‹ä¸€èŠ‚è®²è§£ã€‚

- `BlobServer`ï¼šå®ç°äº† BOLB serverï¼Œå…¶ä¼šç›‘å¬æ”¶åˆ°çš„ requestsï¼Œå¹¶ä¼šåˆ›å»º ç›®å½•ç»“æ„å­˜å‚¨ BLOBS ã€æŒä¹…åŒ–ã€‘æˆ–è€…ä¸´æ—¶æ€§çš„ç¼“å­˜ä»–ä»¬
- `InstanceManager`ï¼šTaskManageråœ¨`flink`æ¡†æ¶å†…éƒ¨è¢«å«åš`Instance`ï¼Œflinké€šè¿‡`InstanceManager`ç®¡ç† flink é›†ç¾¤ä¸­å½“å‰æ‰€æœ‰æ´»è·ƒçš„ TaskManagerï¼ŒåŒ…æ‹¬æ¥æ”¶å¿ƒè·³ï¼Œé€šçŸ¥ InstanceListener Instance çš„ç”Ÿæˆä¸æ­»äº¡ï¼Œä¸€ä¸ªå…¸å‹çš„ `InstanceListener` ä¸º flink çš„ Scheduler
- `BlobLibraryCacheManager`ï¼šflink job çš„ jar åŒ…å­˜å‚¨æœåŠ¡ï¼Œä½¿ç”¨ä¸Šé¢çš„ BlobServer å®Œæˆã€‚
- `MemoryArchivist`å¤‡æ¡ˆå·²æäº¤çš„flinkä½œä¸šï¼ŒåŒ…æ‹¬`JobGraph`ã€`ExecutionGraph`ç­‰
- â€‹
- `ZooKeeperCompletedCheckpointStore`ï¼šè´Ÿè´£æŒä¹…åŒ– job çš„ checkpoint ä¿¡æ¯ï¼Œä¸€ä¸ª job å¯ä»¥æŒä¹…åŒ–å¤šä¸ª checkpointï¼Œä½†åªæœ‰æœ€æ–°çš„ä¼šè¢«ä½¿ç”¨ï¼Œå…·ä½“æ–¹å¼ä¸ºå…ˆåœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æŒä¹…åŒ–ä¸€ä»½ï¼Œå†å°†æ–‡ä»¶å¥æŸ„æ›´æ–°åˆ° zkï¼Œå¹¶åœ¨ zkä¸Šä¾æ¬¡é€’å¢èŠ‚ç‚¹è·¯å¾„å·ï¼Œzk ä¸Šä¿å­˜äº†æœ€è¿‘çš„ 10 æ¬¡ checkpoint
- SavepointStoreï¼šflink çš„çŠ¶æ€å­˜å‚¨ï¼Œè´Ÿè´£å­˜å‚¨ç®—å­å†…éƒ¨å®šä¹‰çš„çŠ¶æ€ï¼Œä¸ checkpoint ç¨æœ‰åŒºåˆ«ï¼Œåè€…ç”± flink æ¡†æ¶æ¥ç»´æŠ¤

*ä¸ºäº†å¯¹`JobManager`ä¸­æ‰€èµ·çš„ actors æœåŠ¡æœ‰æ‰€äº†è§£ï¼Œè¿™é‡Œç®€å•ä»‹ç»ä¸‹`JobManager`çš„å¯åŠ¨è¿‡ç¨‹*

ç®€å•åˆ†æå¾—çŸ¥`line2049: runJobManager`æ˜¯JobManagerå¯åŠ¨çš„å…¥å£ï¼Œåœ¨è·å–`JobManager`å¯åŠ¨çš„ä¸»æœºå’Œç«¯å£åï¼Œå˜å¼€å§‹å¯åŠ¨ actor systemï¼Œweb uiä»¥åŠå…¶ä»– actorsï¼š

```java
//JobManager line2008
def runJobManager(
    configuration: Configuration,
    executionMode: JobManagerMode,
    listeningAddress: String,
    listeningPort: Int)
  : Unit = {

  val (jobManagerSystem, _, _, webMonitorOption, _) = startActorSystemAndJobManagerActors(
    configuration,
    executionMode,
    listeningAddress,
    listeningPort,
    classOf[JobManager],
    classOf[MemoryArchivist],
    Option(classOf[StandaloneResourceManager])
  )

  // block until everything is shut down
  jobManagerSystem.awaitTermination()
```

å…·ä½“çš„å¯åŠ¨é€»è¾‘åœ¨`startActorSystemAndJobManagerActors`æ–¹æ³•ä¸­ï¼š

```java
//JobManager line2150
def startActorSystemAndJobManagerActors(
    configuration: Configuration,
    executionMode: JobManagerMode,
    listeningAddress: String,
    listeningPort: Int,
    jobManagerClass: Class[_ <: JobManager],
    archiveClass: Class[_ <: MemoryArchivist],
    resourceManagerClass: Option[Class[_ <: FlinkResourceManager[_]]])
  : (ActorSystem, ActorRef, ActorRef, Option[WebMonitor], Option[ActorRef]) = {
  ...
```

ç®€å•åˆ—ä¸¾ä¸‹é€»è¾‘ï¼š

- JobManager ç¨‹åºçš„ä¸»å…¥å£ï¼Œç”± ApplicationMasterBase å‘èµ·
- line 2174 ä½¿ç”¨ Json é…ç½® Akka å¹¶ç”Ÿæˆ ActorSystem
- line 2197 åˆå§‹åŒ– ZooKeeperLeaderRetrievalServiceï¼ŒJobManageråœ¨å¯åŠ¨çš„æ—¶å€™ä¼šä»¥ LeaderRetrievalListener çš„èº«ä»½å°†è‡ªå·±æ³¨å†Œè¿›æ¥ï¼Œè¯¥ service è´Ÿè´£ç›‘å¬æœ€æ–°çš„ leader ä¿¡æ¯ï¼Œå½“å‘ç”Ÿæ”¹å˜æ—¶ é€šçŸ¥æ‰€æœ‰ listenerã€æ‰€æœ‰çš„ JobManagerã€‘
- line 2220 å¯åŠ¨ YarnJobManager å’Œ MemoryArchivist actorsã€è¿™é‡Œå¹¶æ²¡æœ‰å¯åŠ¨ã€‘
- line2268 å¯åŠ¨ã€flinkåŸºæœ¬ç»„ä»¶å’ŒJobGraphçš„ç”Ÿæˆä¸€èŠ‚ä¸­æåˆ°çš„ã€‘FlinkResourceManager
- line 2620 createJobManagerComponents è·å–ä»¥ä¸Šä¸¤ä¸ªç»„ä»¶å¿…è¦çš„é…ç½®ï¼Œå¹¶åˆå§‹åŒ–ç›¸å…³æœåŠ¡ å…·ä½“è§ã€ flink JobManager ä¸­æ‰€èµ·çš„æœåŠ¡ã€‘è¿™é‡Œåœ¨åˆå§‹åŒ–ç›¸å…³ç»„ä»¶åä¼šåˆå§‹åŒ– JobManagerï¼Œakka actorOf æ–¹æ³•ä¼ å…¥çš„å±æ€§ä¸ºæ„é€ å™¨ä¸­å‚æ•°ï¼Œé‡è½½ preStart å’Œ postStop æ–¹æ³•ä¼šåœ¨ actor å¯åŠ¨å’Œå…³é—­å ç›¸ç»§æ‰§è¡Œï¼ŒJobManager ä¼šåœ¨è¿™ä¸¤ä¸ªæ–¹æ³•ä¸­å¯åŠ¨å’Œåœæ­¢è¿™äº›æœåŠ¡

åˆ°è¿™é‡Œä¸€ä¸ªå®Œæ•´çš„`JobManager` actor ä¾¿å¯åŠ¨èµ·æ¥äº†ğŸ˜œ

æ—¢ç„¶æ˜¯ actor ï¼Œé‚£ä¹ˆä»–çš„æ ¸å¿ƒé€»è¾‘ä¸€å®šæ˜¯å„ç§æ¶ˆæ¯çš„è·¯ç”±å’Œå¤„ç†ï¼š

```java
//JobManager line304
override def handleMessage: Receive = {

  case GrantLeadership(newLeaderSessionID) =>
    log.info(s"JobManager $getAddress was granted leadership with leader session ID " +
      s"$newLeaderSessionID.")

    leaderSessionID = newLeaderSessionID
```

ä»‹ç»ä¸‹è¿™é‡Œæ¯”è¾ƒé‡è¦çš„å‡ ç§æ¶ˆæ¯ï¼š

- å¤„ç†æ¶ˆæ¯çš„æ ¸å¿ƒæ–¹æ³•
- GrantLeadership è·å¾—leaderæˆæƒï¼Œå°†è‡ªèº«è¢«åˆ†å‘åˆ°çš„ session id å†™åˆ° zookeeperï¼Œå¹¶æ¢å¤æ‰€æœ‰çš„ jobs.
- RevokeLeadership å‰¥å¤ºleaderæˆæƒï¼Œæ‰“æ–­æ¸…ç©ºæ‰€æœ‰çš„ job ä¿¡æ¯ï¼Œä½†æ˜¯ä¿ç•™ä½œä¸šç¼“å­˜ï¼Œæ³¨é”€æ‰€æœ‰çš„ TaskManagers.Â 
- RegisterTaskManagers æ³¨å†Œ TaskManagerï¼Œå¦‚æœä¹‹å‰å·²ç»æ³¨å†Œè¿‡ï¼Œåˆ™åªç»™å¯¹åº”çš„ Instance å‘é€æ¶ˆæ¯ï¼Œå¦åˆ™å¯åŠ¨æ³¨å†Œé€»è¾‘ï¼šåœ¨ InstanceManager ä¸­æ³¨å†Œè¯¥ Instance çš„ä¿¡æ¯ï¼Œå¹¶åœæ­¢ Instance BlobLibraryCacheManager çš„ç«¯å£ã€ä¾›ä¸‹è½½ lib åŒ…ç”¨ã€‘ï¼ŒåŒæ—¶ä½¿ç”¨ watch ç›‘å¬ task manager çš„å­˜æ´»
- SubmitJob æäº¤ jobGraph

### æ‰§è¡Œè®¡åˆ’ ExecutionGraph çš„ç”Ÿæˆ

flink çš„è¿è¡Œæ—¶æ‰§è¡Œè®¡åˆ’ä¸º ExecutionGraphï¼ŒExecutionGraph å¯¹åº”ä¹‹å‰çš„ JobGraphï¼Œä¸€ä¸ª ExecutionGraph åŒ…å«å¤šä¸ª ExecutionJobVertex èŠ‚ç‚¹ï¼ŒJobGraph çš„ JobVertexï¼Œæ¯ä¸ª ExecutionJobVertex èŠ‚ç‚¹çš„å¹¶å‘å­ task å¯¹åº”ä¸€ä¸ª ExecutionVertexï¼Œæ¯ä¸ª ExecutionVertex çš„ä¸€æ¬¡ attempt æ‰§è¡Œè¢«æŠ½è±¡ä¸ºä¸€æ¬¡ Executionï¼Œå…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![flink-job-vertex-to-execution.png](flink-job-vertex-to-execution.png)

*ä¸‹é¢ä¼šå¯¹æ¯ä¸ªæŠ½è±¡åšè¯¦ç»†çš„ä»‹ç»*

ExecutionGraph çš„åˆ›å»ºæ˜¯åœ¨ JobManager æ¥æ”¶ SubmitJob å‘½ä»¤åå¼€å§‹çš„ï¼Œè¿™æ¡æ¶ˆæ¯ä¼šè¢«è·¯ç”±åˆ°æ–¹æ³•ï¼š

```java
//JobManager line1048
private def submitJob(jobGraph: JobGraph, jobInfo: JobInfo, isRecovery: Boolean = false): Unit = {
  if (jobGraph == null) {
    jobInfo.client ! decorateMessage(JobResultFailure(
      new SerializedThrowable(
        new JobSubmissionException(null, "JobGraph must not be null.")
      )
    ))
  }
```

å…¶é€»è¾‘æ€»ç»“å¦‚ä¸‹ï¼š

- æäº¤ä½œä¸š
- å…·ä½“çš„ç»„ä»¶äº¤äº’è¿‡ç¨‹ Client.java line169 runBlocking -> JobClient.java line102 submitJobAndWait -> JobClientActor.java line 337 tryToSubmitJob Â è¿™é‡Œä¼šå…ˆä¸Šä¼  jars åˆ° JobManager çš„ BlobServerï¼Œç„¶åå‘èµ·æäº¤å‘½ä»¤
- line1068: è®¾ç½®ç”¨æˆ·libåŒ…ï¼Œä½¿ç”¨ Â LibraryCacheManager book job çš„jaråŒ…ï¼Œç”±äºä¹‹å‰åŒ…å·²ä¸Šä¼ ï¼Œè¿™ä¼šåˆ›å»ºjobId å’Œ jars ä»¥åŠclass paths çš„å¯¹åº”å…³ç³»
- line1114: å°† JobGraph è½¬æ¢ä¸º ExecutionGraph é€»è¾‘è®¡åˆ’è½¬åŒ–ä¸ºç‰©ç†è®¡åˆ’ã€åè€…ç»´æŠ¤ data flow çš„åè°ƒæ‰§è¡Œã€è¿æ¥ã€è®¡ç®—ä¸­é—´ç»“æœã€‘å…·ä½“è§ç« èŠ‚ï¼š flink runtime
- line 1178 ExecutionJobVertex åœ¨æ­¤å¤„ç”Ÿæˆï¼Œé€šè¿‡ JobGraph ä¾ç…§æ•°æ®æºé¡ºåºè·å–ä¸‹æ¸¸ JobVertexï¼Œå…·ä½“ç®—æ³•å¦‚ä¸‹ï¼š

![job-graph-node-sort.png](job-graph-node-sort.png)

flinkæ’åºèŠ‚ç‚¹çš„é¡ºåºï¼š

- æ•°æ®æºèŠ‚ç‚¹
- åªæœ‰ä¸€ä¸ªä¸Šæ¸¸çš„èŠ‚ç‚¹
- sinkèŠ‚ç‚¹

*ä¾‹å¦‚ä¸Šå›¾çš„ä¸¤ä¸ªæ‹“æ‰‘ç»“æ„ï¼Œå·¦è¾¹èŠ‚ç‚¹æ’åºå®Œçš„é¡ºåºä¸ºï¼š 1 2 3 4 5 å³è¾¹çš„èŠ‚ç‚¹æ’åºå®Œçš„é¡ºåºä¸ºï¼š1 2 3 5 4 6*

é‚£ä¹ˆ flink ä¸ºä»€ä¹ˆè¦å°† JobGraph è½¬æ¢ä¸º ExecutionGraph ï¼Œå¹¶ä¸”æ’åºè¿™äº›èŠ‚ç‚¹å‘¢ï¼ŸExecutionGraph ä»£è¡¨äº†è¿è¡Œæ—¶çš„æ‰§è¡Œè®¡åˆ’ï¼ŒåŒ…æ‹¬ task çš„å¹¶å‘ã€è¿æ¥ã€ä¸­é—´ç»“æœçš„ç»´æŠ¤ç­‰ï¼Œæ’åºçš„ç›®çš„æ˜¯ç»™ task çš„éƒ¨ç½²è®¾ç½®å…ˆåé¡ºåºï¼Œæƒ³æ¥ä¹Ÿæ˜¯å¾ˆè‡ªç„¶çš„ã€‚æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ ExecutionGraph çš„æ„é€ å™¨å°±èƒ½äº†è§£ä¸ªå¤§æ¦‚ï¼š

```java
public ExecutionGraph(
      ExecutionContext executionContext,
      JobID jobId,
      String jobName,
      Configuration jobConfig,
      SerializedValue<ExecutionConfig> serializedConfig,
      FiniteDuration timeout,
      RestartStrategy restartStrategy,
      List<BlobKey> requiredJarFiles,
      List<URL> requiredClasspaths,
      ClassLoader userClassLoader,
      MetricGroup metricGroup) {

   ...

   this.executionContext = executionContext;

   this.jobID = jobId;
   this.jobName = jobName;
   this.jobConfiguration = jobConfig;
   this.userClassLoader = userClassLoader;

   this.tasks = new ConcurrentHashMap<JobVertexID, ExecutionJobVertex>();
   this.intermediateResults = new ConcurrentHashMap<IntermediateDataSetID, IntermediateResult>();
   this.verticesInCreationOrder = new ArrayList<ExecutionJobVertex>();
   this.currentExecutions = new ConcurrentHashMap<ExecutionAttemptID, Execution>();

   this.jobStatusListenerActors  = new CopyOnWriteArrayList<ActorGateway>();
   this.executionListenerActors = new CopyOnWriteArrayList<ActorGateway>();

   this.stateTimestamps = new long[JobStatus.values().length];
   this.stateTimestamps[JobStatus.CREATED.ordinal()] = System.currentTimeMillis();

   this.requiredJarFiles = requiredJarFiles;
   this.requiredClasspaths = requiredClasspaths;

   this.serializedExecutionConfig = checkNotNull(serializedConfig);

   this.timeout = timeout;

   this.restartStrategy = restartStrategy;

   metricGroup.gauge(RESTARTING_TIME_METRIC_NAME, new RestartTimeGauge());
}
```

ä»æ„é€ å™¨å¯ä»¥çœ‹å‡ºï¼ŒExecutionGraph ä¼šç»´æŠ¤å½“å‰çš„é€»è¾‘è®¡åˆ’ä¿¡æ¯ã€å°±æ˜¯æœ‰å“ªäº›taskè¦æ‰§è¡Œã€‘ã€ä¸­é—´ç»“æœç”Ÿæˆä¿¡æ¯ï¼Œå½“å‰æ­£åœ¨è¿è¡Œçš„ taskï¼Œè´Ÿè´£ job å’Œ task çŠ¶æ€åˆ‡æ¢çš„é€šçŸ¥ç­‰ã€‚

#### æ‰§è¡Œè®¡åˆ’èŠ‚ç‚¹ ExecutionJobVertex çš„ç”Ÿæˆ

attachJobGraph æ˜¯ ExecutionGraph æ„é€ å›¾ç»“æ„çš„æ ¸å¿ƒæ–¹æ³•ï¼Œè€Œå…¶ä¸­æœ€å…³é”®çš„é€»è¾‘æ˜¯ æ‰§è¡ŒèŠ‚ç‚¹ ExecutionJobGraph çš„åˆ›å»ºï¼Œä¸‹é¢è¯¦ç»†åˆ†æä¸‹å…¶åˆ›å»ºè¿‡ç¨‹å’Œæ ¸å¿ƒåŠŸèƒ½ï¼š

```java
//ExecutionJobVertex line95
public ExecutionJobVertex(ExecutionGraph graph, JobVertex jobVertex,
                  int defaultParallelism, FiniteDuration timeout, long createTimestamp)
      throws JobException
{
   ...
   this.graph = graph;
   this.jobVertex = jobVertex;
   
   int vertexParallelism = jobVertex.getParallelism();
   int numTaskVertices = vertexParallelism > 0 ? vertexParallelism : defaultParallelism;
   
   this.parallelism = numTaskVertices;
   this.taskVertices = new ExecutionVertex[numTaskVertices];
   
   this.inputs = new ArrayList<IntermediateResult>(jobVertex.getInputs().size());
   
   // take the sharing group
   this.slotSharingGroup = jobVertex.getSlotSharingGroup();
   this.coLocationGroup = jobVertex.getCoLocationGroup();
   ...
   
   // create the intermediate results
   this.producedDataSets = new IntermediateResult[jobVertex.getNumberOfProducedIntermediateDataSets()];

   for (int i = 0; i < jobVertex.getProducedDataSets().size(); i++) {
      final IntermediateDataSet result = jobVertex.getProducedDataSets().get(i);

      this.producedDataSets[i] = new IntermediateResult(
            result.getId(),
            this,
            numTaskVertices,
            result.getResultType(),
            result.getEagerlyDeployConsumers());
   }

   // create all task vertices
   for (int i = 0; i < numTaskVertices; i++) {
      ExecutionVertex vertex = new ExecutionVertex(this, i, this.producedDataSets, timeout, createTimestamp);
      this.taskVertices[i] = vertex;
   }
   ...
   
   // set up the input splits, if the vertex has any
   try {
      @SuppressWarnings("unchecked")
      InputSplitSource<InputSplit> splitSource = (InputSplitSource<InputSplit>) jobVertex.getInputSplitSource();
      
      if (splitSource != null) {
         inputSplits = splitSource.createInputSplits(numTaskVertices);
         
         if (inputSplits != null) {
            if (splitSource instanceof StrictlyLocalAssignment) {
               inputSplitsPerSubtask = computeLocalInputSplitsPerTask(inputSplits);
               splitAssigner = new PredeterminedInputSplitAssigner(inputSplitsPerSubtask);
            } else {
               splitAssigner = splitSource.getInputSplitAssigner(inputSplits);
            }
         }
      }
      else {
         inputSplits = null;
      }
   }
   catch (Throwable t) {
      throw new JobException("Creating the input splits caused an error: " + t.getMessage(), t);
   }
   
   finishedSubtasks = new boolean[parallelism];
}
```

ç®€è¦ä»‹ç»ä¸‹å…¶æ„å»ºé€»è¾‘ï¼š

- ä¾æ®å¯¹åº”çš„ JobVetex çš„å¹¶å‘ç”Ÿæˆå¯¹åº”ä¸ªæ•°çš„ ExecutionVertexï¼Œä¸€ä¸ª ExecutionVertex ä»£è¡¨ä¸€ä¸ª ExecutionJobVertex çš„å¹¶å‘å­ task
- è®¾ç½® SlotSharingGroup å’Œ CoLocationGroupï¼Œè¿™ä¸¤ä¸ªç»„ä»¶æ˜¯ flink è¿è¡Œæ—¶ä»»åŠ¡è°ƒåº¦çš„æ ¸å¿ƒæŠ½è±¡ï¼Œä¼šçº¦æŸ flink è°ƒåº¦ task çš„ç­–ç•¥ï¼Œåœ¨ flink ä»»åŠ¡è°ƒåº¦ç®—æ³• ä¸€èŠ‚ä¼šè¯¦ç»†ä»‹ç»
- å°†åŸæ¥ JobVertex çš„ä¸­é—´ç»“æœ IntermediateDataSet è½¬åŒ–ä¸º IntermediateResultï¼Œåè€…åœ¨å‰è€…çš„åŸºç¡€ä¸ŠåŠ å…¥äº† å½“å‰æ­£åœ¨è¿è¡Œçš„ producer ä¿¡æ¯ï¼Œæ˜¯çœŸæ­£å…³äºè¿è¡Œæ—¶ä¸­é—´æ•°æ®çš„æŠ½è±¡
- å¦‚æœå¯¹åº”çš„ job èŠ‚ç‚¹æ˜¯æ•°æ®æºèŠ‚ç‚¹ï¼Œä¼šè·å–å…¶ InputSplitSourceï¼ŒInputSplitSource æ§åˆ¶äº†æ•°æ®æºå¹¶å‘å­ task å’Œç”Ÿäº§çš„ InputSplit çš„å¯¹åº”å…³ç³»ï¼Œä¸€ä¸ª InputSplit ä»£è¡¨ä¸€ä¸ªæ•°æ®æºåˆ†ç‰‡ï¼Œå¯¹äº flink streaming æ¥è¯´ï¼ŒInputSplitSource å°±æ˜¯ä¸€ä¸ª InputFormatï¼Œå¯¹åº”ä¸€ä¸ªè¾“å…¥æº task 
- è¿™é‡Œçš„ InputSplitSource æ˜¯åœ¨ä»€ä¹ˆæ—¶å€™è®¾ç½®è¿›å»çš„å‘¢ï¼Ÿè§`JobManager line1163 vertex.initializeOnMaster(userCodeLoader)`ä»¥åŠ`StreamingJobGraphGenerator.java line 278Â createDataSourceVertexÂ `

#### æ‰§è¡Œè®¡åˆ’èŠ‚ç‚¹ ExecutionJobVertex çš„è¿æ¥

æ„å»ºå®ŒèŠ‚ç‚¹åé€šè¿‡è¿æ¥ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ DAGã€è§ExecutionGraph attachJobGraph æ–¹æ³•ã€‘ï¼ŒconnectToPredecessors æ˜¯è¿æ¥æ‰§è¡ŒèŠ‚ç‚¹çš„æ ¸å¿ƒé€»è¾‘ï¼š

```java
//ExecutionJobGraph line237
public void connectToPredecessors(Map<IntermediateDataSetID, IntermediateResult> intermediateDataSets) throws JobException {
   
   List<JobEdge> inputs = jobVertex.getInputs();
   
   ...
   
   for (int num = 0; num < inputs.size(); num++) {
      JobEdge edge = inputs.get(num);
      
      ...
      
      // fetch the intermediate result via ID. if it does not exist, then it either has not been created, or the order
      // in which this method is called for the job vertices is not a topological order
      IntermediateResult ires = intermediateDataSets.get(edge.getSourceId());
      if (ires == null) {
         throw new JobException("Cannot connect this job graph to the previous graph. No previous intermediate result found for ID "
               + edge.getSourceId());
      }
      
      this.inputs.add(ires);
      
      int consumerIndex = ires.registerConsumer();
      
      for (int i = 0; i < parallelism; i++) {
         ExecutionVertex ev = taskVertices[i];
         ev.connectSource(num, ires, edge, consumerIndex);
      }
   }
}
```

ç®€è¦æ¦‚æ‹¬é€»è¾‘å¦‚ä¸‹ï¼š

- è®¾ç½®è¾“å…¥ IntermediateResult
- å°†è‡ªå·±æ³¨å†Œåˆ°  IntermediateResultï¼Œç›®å‰ä¸€ä¸ª IntermediateResult åªæ”¯æŒä¸€ä¸ª æ¶ˆè´¹ ExecutionJobVertex èŠ‚ç‚¹
- è®¾ç½®å¹¶å‘å­ task ExecutionVertex å’Œä¸­é—´ç»“æœ IntermediateResult çš„è¿æ¥å…³ç³»ï¼Œé€šè¿‡ ExecutionVertex çš„ connectSource Â æ–¹æ³•è®¾ç½® ExecutionVertex çš„è¿æ¥ç­–ç•¥ï¼Œç­–ç•¥ä¸€å…±ä¸¤ç§ï¼š POINT_WISE ALL_TO_ALL å‰è€…ä¸Šæ¸¸ partition ä¸ä¸‹æ¸¸ consumers ä¹‹é—´æ˜¯ä¸€å¯¹å¤šå…³ç³»ï¼Œåè€…æ˜¯ all to all å…³ç³»ï¼Œè¿™é‡Œä¼šå°† ExecutionEdge åˆ›å»ºå‡ºæ¥å¹¶æ·»åŠ  consumer ä¸ºæ­¤ edgeã€partitionåœ¨ new ExecutionVertexæ—¶åˆ›å»ºå‡ºæ¥ï¼Œç”± ExecutionVertex æ„é€ å™¨å¯çŸ¥ä¸€ä¸ª ExecutionVertex ç”Ÿäº§ä¸€ä¸ª partitionï¼Œpartition number å°±æ˜¯ sub task indexã€‘

#### æ‰§è¡ŒèŠ‚ç‚¹å­ä»»åŠ¡ ExecutionVertex

å…ˆçœ‹ä¸€ä¸‹ ExecutionVertex çš„åˆ›å»ºè¿‡ç¨‹ï¼š

```java
public ExecutionVertex(
      ExecutionJobVertex jobVertex,
      int subTaskIndex,
      IntermediateResult[] producedDataSets,
      FiniteDuration timeout,
      long createTimestamp) {
   this.jobVertex = jobVertex;
   this.subTaskIndex = subTaskIndex;

   this.resultPartitions = new LinkedHashMap<IntermediateResultPartitionID, IntermediateResultPartition>(producedDataSets.length, 1);

   for (IntermediateResult result : producedDataSets) {
      IntermediateResultPartition irp = new IntermediateResultPartition(result, this, subTaskIndex);
      result.setPartition(subTaskIndex, irp);

      resultPartitions.put(irp.getPartitionId(), irp);
   }

   this.inputEdges = new ExecutionEdge[jobVertex.getJobVertex().getInputs().size()][];

   this.priorExecutions = new CopyOnWriteArrayList<Execution>();

   this.currentExecution = new Execution(
      getExecutionGraph().getExecutionContext(),
      this,
      0,
      createTimestamp,
      timeout);

   // create a co-location scheduling hint, if necessary
   CoLocationGroup clg = jobVertex.getCoLocationGroup();
   if (clg != null) {
      this.locationConstraint = clg.getLocationConstraint(subTaskIndex);
   }
   else {
      this.locationConstraint = null;
   }

   this.timeout = timeout;
}
```

é€»è¾‘æ€»ç»“å¦‚ä¸‹ï¼š

- ä¾æ®å¯¹åº”çš„ ExecutionJobGraph ç”Ÿæˆçš„ä¸­é—´æ•°æ®é›† IntermediateResult çš„ä¸ªæ•°ç”Ÿæˆä¸€å®šä¸ªæ•°çš„ partitionï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ª IntermediateResult è¾“å‡ºä¸€ä¸ª partition
- ç”Ÿæˆ Execution
- é…ç½®èµ„æºç›¸å…³

ä¸‹é¢é‡ç‚¹ä»‹ç»ä¸‹å…¶è¿æ¥ä¸Šæ¸¸ ExecutionVertex çš„è¿‡ç¨‹ï¼š

connectSource æ˜¯è¿æ¥çš„æ ¸å¿ƒé€»è¾‘ï¼Œé€»è¾‘å¦‚ä¸‹:

```java
//ExecutionVertex line250
public void connectSource(int inputNumber, IntermediateResult source, JobEdge edge, int consumerNumber) {

   final DistributionPattern pattern = edge.getDistributionPattern();
   final IntermediateResultPartition[] sourcePartitions = source.getPartitions();

   ExecutionEdge[] edges;

   switch (pattern) {
      case POINTWISE:
         edges = connectPointwise(sourcePartitions, inputNumber);
         break;

      case ALL_TO_ALL:
         edges = connectAllToAll(sourcePartitions, inputNumber);
         break;

      default:
         throw new RuntimeException("Unrecognized distribution pattern.");

   }

   this.inputEdges[inputNumber] = edges;

   // add the consumers to the source
   // for now (until the receiver initiated handshake is in place), we need to register the 
   // edges as the execution graph
   for (ExecutionEdge ee : edges) {
      ee.getSource().addConsumer(ee, consumerNumber);
   }
}
```

é€»è¾‘æ€»ç»“å¦‚ä¸‹ï¼š

- è·å– JobEdge çš„æ•°æ®åˆ†å‘ç­–ç•¥ï¼šå¦‚æœé shuffle æ“ä½œå°±æ˜¯ DistributionPattern.POINTWISE å¦åˆ™æ˜¯ DistributionPattern.ALL_TO_ALLå…·ä½“è§ä»£ç ï¼š

```java
//StreamingJobGraphGenerator line370
StreamPartitioner<?> partitioner = edge.getPartitioner();
if (partitioner instanceof ForwardPartitioner) {
   downStreamVertex.connectNewDataSetAsInput(
      headVertex,
      DistributionPattern.POINTWISE,
      ResultPartitionType.PIPELINED,
      true);
} else if (partitioner instanceof RescalePartitioner){
   downStreamVertex.connectNewDataSetAsInput(
      headVertex,
      DistributionPattern.POINTWISE,
      ResultPartitionType.PIPELINED,
      true);
} else {
   downStreamVertex.connectNewDataSetAsInput(
         headVertex,
         DistributionPattern.ALL_TO_ALL,
         ResultPartitionType.PIPELINED,
         true);
}
```

- æŒ‰ç…§ä¸åŒçš„åˆ†å‘ç­–ç•¥è¿æ¥ä¸Šæ¸¸

DistributionPattern.ALL_TO_ALL å°±æ˜¯ç®€å•çš„å…¨è¿æ¥ï¼Œè¿™é‡Œå°±ä¸ä»‹ç»äº†ï¼Œåªä»‹ç»DistributionPattern.POINTWISE ç­–ç•¥ã€‚

è¯¥ç­–ç•¥è¿æ¥ execution vertex ä¸ä¸Šæ¸¸çš„ partitionsï¼Œä¼šå…ˆè·å–ä¸Šæ¸¸çš„ partition æ•°ä¸ æ­¤ ExecutionJobVertex çš„å¹¶å‘åº¦ï¼Œå¦‚æœä¸¤è€…å¹¶å‘åº¦ç›¸ç­‰ï¼Œåˆ™æ˜¯ ä¸€å¯¹ä¸€ è¿æ¥ï¼š

![execution-vertex-one-to-one.png](execution-vertex-one-to-one.png)

å¦‚æœ partition æ•°å°äº å¹¶å‘æ•° ï¼Œå­ task åªä¼šè¿æ¥ä¸€ä¸ªä¸Šæ¸¸ partitionï¼Œå…·ä½“å…³ç³»å¦‚ä¸‹å›¾ï¼š

![execution-one-many.png](execution-one-many.png)

å¦‚æœ partition æ•°å¤§äºå¹¶å‘æ•°ï¼Œå­ task ä¼šè¿æ¥å¤šä¸ªä¸Šæ¸¸ partitionï¼Œå…·ä½“è§ä¸‹å›¾ï¼š

![execution-many-one.png](execution-many-one.png)

åˆ°è¿™é‡Œè¿è¡Œæ—¶æ‰§è¡Œè®¡åˆ’ ExecutionGraph çš„ç”Ÿæˆå°±ä»‹ç»å®Œäº†ğŸ˜„ä¸‹èŠ‚å°†å…ˆä»‹ç» JobManager çš„æ ¸å¿ƒç»„ä»¶